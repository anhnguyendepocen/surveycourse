\documentclass[11pt,a4paper]{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{graphicx,setspace,hyperref,amsmath,amsfonts,multirow,ccaption,mdwlist,comment}
% mini table of contents
\usepackage{minitoc}
\dosecttoc % make section toc
\setcounter{secttocdepth}{2} % subsection depth
\renewcommand{\stctitle}{} % no title
\nostcpagenumbers

% optionally include commented environments
\excludecomment{lessonplan}

\setlength{\marginparwidth}{.5in}
\usepackage{natbib}
% Two lines to create in-text full citations for a syllabus
% And comment out my other standard bibtex commands
\usepackage{bibentry}
\newcommand{\reading}[2][]{\noindent -- {#1}\bibentry{#2}.\vspace{.25em}\\}
\newcommand{\textbook}[2][]{\noindent -- {#1} from Groves et al.\vspace{.25em}\\} % textbook reference
\newcommand{\seealso}{\noindent \emph{See Also:}\\}
\newcommand{\topic}[1]{\noindent \textbf{#1}\\}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    unicode=false,          % non-Latin characters in Acrobat’s bookmarks
    pdftoolbar=true,        % show Acrobat’s toolbar?
    pdfmenubar=true,        % show Acrobat’s menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={Syllabus: Using Surveys for Research and Evaluation},    % title
    pdfauthor={Thomas J. Leeper},     % author
    pdfsubject={Political Science},   % subject of the document
    pdfnewwindow=true,      % links in new window
    pdfborder={0 0 0}
}

\title{Using Surveys for Research and Evaluation}
\author{Thomas J. Leeper\\
Department of Political Science and Government\\
Aarhus University}

\begin{document}
\nobibliography*

\maketitle

\faketableofcontents

%\section{Introduction}

Almost every organization --- public or private --- conducts surveys to understand their customers, clients, constituents, research subjects, and the public at-large. Surveys are therefore a critically important methodological tool for conducting empirical political science research and for evaluating policy, performance, and impact. Nearly every political science student will, in the course of their future career, have to conduct, analyze, or interpret survey-based research.

How do we conduct surveys well so that they provide meaningful insights? How do we write survey questions so that respondents understand them and that those responses generate useful data about relevant constructs? How do we decide whom to interview and how do we interview them effectively? How do we prepare for and manage the implementation of a large survey? How do we analyze the obtained results? This course will provide answers to these questions while training students how to implement a survey data collection and analyze the results thereof. The exam will entail the design, preparation, and pilot testing of a survey on the topic of student's choice.

\section{Objectives}
The learning objectives for the course are as follows. By the end of the course, students should be able to:

\begin{enumerate}
\item Identify and analyze the usefulness of survey methods for conducting research and evaluating programs, policies, and outcomes
\item Identify sources of error and bias in surveys
\item Explain how sampling procedures enable estimation of population parameters and evaluate the implications of differences in sampling techniques
\item Demonstrate how to successfully manage large survey data collection efforts
\item Evaluate the quality of surveys in terms of sampling, interviewing procedures, and questionnaire content 
\item Apply methodological and substantive knowledge from the course to the design and implementation of an original survey
\end{enumerate}

\section{Exam and Weekly Assignments}
The exam for the course involves a home assignment, totaling 6000 words.\footnote{Students can, optionally, collaborate in teams of two or three to write a longer exam paper (in accordance with study regulations). Students planning a collaborative project should consult with the instructor early in the course.} The exam will take the form of an essay that describes a research question, hypotheses, sampling design, operationalization of constructs, implementation plan, and pilot testing of a proposed survey. A complete questionnaire for that survey, including exact question wordings of all core constructs, must be created and included as a supplemental appendix to the exam paper. Students are welcome to meet with the instructor near the end of the semester to discuss their survey and and exam paper. Final presentations during the last two weeks of the course allow for additional peer feedback.

While officially due at the end of the course, each requisite portion of the exam can be completed during the semester in the form of weekly written assignments that progressively evaluate student learning. As such, the exam is a ``portfolio'' of these earlier assignments, which will need to be made into a single, coherent, finished product reflecting peer and instructor feedback from earlier. The exam paper should also include a concluding section (up to one page) reflecting on the evolution of the survey plan from its initial origins at the beginning of the course to its final state, with emphasis on how what you learned in the course influenced the final survey design.

Details on the weekly assignments are listed in the course schedule. Assignments are due on the day they are described in the schedule.

Finally, students will sign up each week to provide a short, five-minute presentation of one of the (non-textbook) readings and lead a short discussion about its contents and the implications thereof for survey design. Students are expected to give at least two such presentations during the semester.

\section{Course Website}
All information about the course will be posted on \url{http://www.thomasleeper.com/surveycourse}. Any changes to the syllabus or additional notes will be made available there.


%\clearpage
\section{Reading Material}
The assigned material for the course includes a textbook and empirical research articles, all of which are available online or in the printed course packet. All readings should be completed for the day they are described. {\em There is reading assigned on the first day.} The textbook for the course is:\\

\reading{Grovesetal2009}

\clearpage
\section{Schedule}
The general schedule for the course is as follows. Details on the readings for each week are provided on the following pages.

\secttoc

\clearpage


% possible outside people
% Kim: matching survey data to registry data
% Gitte: qualitative interviewing
% Helene: elite interviewing
% Rune: survey experiments
% Stubager: Election study
% Someone from public administration (Lotte?): interviewing public employees



\subsection{No class (Week 36)}
\emph{There is no class in Week 36. However, please start reading the textbook and a short article by Brady providing an overview of survey research in political science. This also gives you additional time to prepare readings and the first short assignment for the first class meeting in Week 37.}
\vspace{1em}

\subsubsection*{Assignment Due}
None. See short assignment for next week.

\subsubsection*{Readings}
\textbook[Ch.1]{}
% some kind of historical overview of survey research in the world
\reading{Brady2000} % overview of surveys in political science
%\seealso




\clearpage
\subsection{What can surveys tell us? (Week 37)}
\emph{What are surveys for? How do they help us to make inferences about things we care about? What different kinds of research designs can leverage surveys?}
% introduction to surveys: why do we do them; what do they tell us; examples
% polling
% election studies
% census measurement (registry; not all countries do)
% media usage (TNS Gallup)
% measure prevalence of something
% assess public views of something
% assess exposure
% pre- and post-event measures (evaluation)
% measure non-individual units: companies, municipalities, organizations, parties
% elite surveys: members of parliament, business leaders, etc.


\vspace{1em}
\subsubsection*{Assignment Due}
Think about a survey you have participated in, either as a respondent or as an interviewer. What was the survey about? How were you recruited to participate in the survey? In one half page, discuss your experience and reflections on the survey experience. Be prepared to share in class.

\subsection*{In-Class Activities}
\begin{itemize*}
\item Introductions and sharing of initial assignments
\item Mostly lecture and discussion
\item Generate and discuss ideas for possible final exam projects
\end{itemize*}

\subsubsection*{Readings}
\textbook[Ch. 2]{} % total survey error
\reading[Ch. 4--5 (103--161) from ]{ShadishCookCampbell2001}
\reading{JohnstonBrady2002}
\reading{Lynnetal2005} % longitudinal
%\reading{DruckmanPetersonSlothuus2013}
% Something explicitly about evaluation?

\seealso
\reading{Sanders2012} % deliberative polls
\reading{GainesKuklinskiQuirk2007} % survey experiments
\reading{Rosenbaum2009}
\reading{Holland1986}






\clearpage
\subsection{Populations and Sampling Frames (Week 38)}
\emph{In order for a survey to provide meaningful statistical inferences, it needs to be conducted on a representative sample of a population of interest. How do we define populations? And how do we sample from them in a valid way?}
\vspace{1em}
\subsubsection*{Assignment Due}
What do you want to know? What is your research question? In one page, describe a topic of interest to political science that you can address with a survey. It can be a question about the prevalence of something (e.g., a condition or behavior), the level of something (e.g., opinions or income), the effect of an intervention on an outcome (e.g., an outcome expected to respond to a randomized treatment or a real-world policy), or similar. Describe your topic and your research question. Then, describe what construct or constructs you need to measure in your survey in order answer your question. Speculate briefly about how you might measure those constructs in a survey.

\subsubsection*{In-Class Activities}
\begin{itemize*}
% possibly have outside people present (Lotte, Stubager, Emily?, Kim?)
% sampling: unit (HH, individual, company, worker, party, municipality, farms, libraries, high school classrooms, etc.); population
% sampling frame: address, telephone (landline, mobile), registry
\item Identifying possible sampling frames for various populations
\item Simple Random Sampling (SRS) from within a frame
\end{itemize*}

\subsubsection*{Readings}
\textbook[Ch. 3]{}
\reading{Heckathorn1997}
\reading{Casseseetal2013}
\reading{Yeageretal2011}
% Danish online panel article?

\seealso
\reading{Lohr2009} % sampling
\reading{ChangKrosnick2009}





\clearpage
\subsection{Sampling Techniques (Week 39)}
\emph{How do we sample from a sampling frame? What are our options for how to gather respondents, and what consequences do those options have for error, costs, and other resources we have available for a survey project? What can we learn from convenience sampling?}

\vspace{1em}
\subsubsection*{Assignment Due}
Find a survey online. This can be any survey (a national election study, a political poll, a survey of childhood health, a survey of political interest organizations, a survey of businesses, etc.). What is the population of units being studied? Was the survey conducted on a representative sample or a convenience sample? Write one half page describing the survey project's research objective, the population, and details how about the sampling frame and sampling process (e.g., were there any issues of coverage, what sampling method was used, etc.). 

\subsubsection*{In-Class Activities}
\begin{itemize*}
% discuss sampling error
% sampling: SRS; quota; cluster; stratified; online panels
\item Mean and proportion estimates, and their variances
\item Practice stratified and cluster sampling from a frame
\item Design effects
\item Discuss trade-offs between representative and convenience sampling
\end{itemize*}

\subsubsection*{Readings}
\textbook[Ch. 4]{}
\reading[Ch. 3 (73--100), 4 (165--199), and 14 (511--526) from ]{Lohr2009} % sampling
\reading{Bakeretal2010}
\reading{Burnhametal2006}
\reading{Reinischetal1995} % registry data
\reading{WalkerEnticott2004} % public administration

\seealso
\reading{Berinskyetal2011}
\reading{BerinskyHuberLenz2012} % convenience sampling




\clearpage
\subsection{Questionnaire Design I (Week 40)}
\emph{How do we write surveys so that the answers we receive from respondents inform us about concepts we care about? What considerations come into play when designing questionnaires and how do we choose between alternative ways of asking about the concepts we care about?}
% constructs and operationalization

\vspace{1em}
\subsubsection*{Assignment Due}
What is your population of cases that you intend to survey? Do you plan to do a census or only interview a sample of the population? If a sample, what is the sampling frame and how did you construct it? How are individuals sampled from your sampling frame? How large of a sample do you plan to collect to obtain sufficiently precise estimates of constructs? In one written page, provide answers to these questions and be prepared to discuss your plans in class.

\subsubsection*{In-Class Activities}
\begin{itemize*}
\item Concept definition
\item Measuring Political (Left--Right) Ideology
\item Measuring factual political knowledge
\item Measuring opinions
% -- response categories (differentials, agree/disagree, ratings, rankings, therms)
\end{itemize*}


\subsubsection*{Readings}
\reading{SchaefferPresser2003} % overview
\reading{AnsolabehereRoddenSnyder2008} % measurement error
\reading{ZallerFeldman1992}
\reading{WilcoxSigelmanCook1989} % thermometers
\reading{KrosnickJuddWittenbrink2005} % -- opinion questions
\reading{Krosnicketal2002} % ``no opinion'' options
\reading{NadeauNiemi1995} % knowledge questions
\reading{Prior2014} % visual political knowledge
\reading{Perry1996} % public service motivation
\reading{KrosnickFabrigar1997} % rating scales

\seealso
\reading{RevillaSarisKrosnick2013}
\reading{MillerOrr2008} % DK options
\reading{LuskinBullock2005}
\reading{JungerTasMarshall1999} % criminal justice




\clearpage
\subsection{Questionnaire Design II (Week 41)}
\emph{How do we know if respondents' answers to our questions our ``correct'' or valid? How can we ask respondents about challenging or sensitive topics in a way that reveals truthful answers? What can experiments in questionnaire design do the inform these decisions?}
% experimental comparison of questions (within and between subjects)

\vspace{1em}
\subsubsection*{Assignment Due}
Given your research question, what are the important constructs that you need to measure? How do you envision operationalizing them as survey questions and response options? Have these constructs been measured in surveys before? If so, how were the questions worded? If there are several options, how will you choose between alternative wordings and response options? In one page provide your answers to these questions.

\subsubsection*{In-Class Activities}
\begin{itemize*}
\item Design a simple experiment to compare alternative question wordings
\item Brainstorm methods of measuring various sensitive questions
\item Design a list experiment for a sensitive question
\end{itemize*}


\subsubsection*{Readings}
\textbook[Ch. 7]{}
% sensitive questions
\reading{TourangeauSmith1996}
\reading{HolbrookKrosnick2010}
\reading{Glynn2013}
\reading{TraugottKatosh1979} % vote validation
\reading{BurtonBlair2011} % reference periods
\reading{Price1993}
\reading{BorgersdeLeeuwHox2000} % child respondents

\seealso
\reading{HolbrookKrosnick2013} % turnout wording
\reading{LeeHuToh2000}



\clearpage
\subsection{No class (Week 42)}



\clearpage
\subsection{Survey Mode (Week 43)}
\emph{In what mode, or format, do respondents provide answers to questions? Survey interviewing was originally entirely face-to-face, with interviewers reading questions aloud and recording answers on paper. With advances in both technology and scientific understanding of survey responding, there are now numerous modes and formats in which respondents can provide answers. What impact does mode have on responding? How does it affect quality, validity, and cost of surveys? And how does mode influence the kinds of questions that can be asked and the way that respondents engage with the survey interview?}

% budgeting
% mixed mode (CASI, cards, randomized response, etc.)
\vspace{1em}

\subsubsection*{Assignment Due}
Be prepared to share and briefly present a complete outline of your questionnaire. This does not need to be finalized, as you may want to add or delete questions, or change question wordings, response categories, or orderings particularly in-light of discussions about survey mode. At this point you simply need to have draft question wordings for your key constructs.

\subsubsection*{In-Class Activities}
\begin{itemize*}
\item Try out different interview modes in pairs
\item Estimate the budget for different modes
%\item Presentation on qualitative interviewing % Gitte?
\end{itemize*}

\subsubsection*{Readings}
\textbook[Ch. 5]{}
\reading{KreuterPresserTourangeau2009}
\reading{MedwayFulton2012} % web response option
\reading{VillarCallegaroYang2013} % online progress meters
\reading{Couperetal2013} % online grids
\reading{SchumanPresser1979} % open and closed 

\seealso
\reading{Smythetal2006} % forced response
\reading{BrewerGross2005} % substantive example




\clearpage
\subsection{Questionnaire Design III (Week 44)}
\emph{Now that you've written a full questionnaire and thought about how you'll gather answers to its questions from respondents, how should you organize questions into a coherent survey interview? Can supplemental data (other than that personally supplied by respondents) benefit your design (e.g., data from public registries, interviewer observations, etc.)?}

% questionnaire length (rolloff; satisficing; quality); split-designs to address length
% question ordering: context effects, break-off, sensitivity
% do respondents provide the same answers in different modes?
% registry data
% paradata
% interviewer-collected data

\vspace{1em}
\subsubsection*{Assignment Due}
In what mode (or modes) do you intend to conduct your survey interviewing? Will respondents have options for how to complete the survey? What do you estimate the time per interview and cost per interview to be for each mode option? What are the benefits and consequences of choosing your proposed survey mode in terms of data quality? In one page, provide answers to these questions and any other considerations relevant to survey mode.

\subsubsection*{In-Class Activities}
\begin{itemize*}
\item Practice collecting interviewer observations during an interview
%\item Presentation about registry data? % Kim
\end{itemize*}


\subsubsection*{Readings}
\reading{TourangeauRasinski1988} % context effects
\reading{BishopOldendickTuchfarber1984} % political interest
\reading[Ch. 2 from ]{SchumanPresser1981}
\reading{GalesicBosnjak2009} % questionnaire length
% Attention check measures
% paradata
\reading{Ottosen2011} % Danish survey-registry match (child study)

\seealso
\reading{SoenderskovDinesen2014} % in Danish, maybe
\reading{DavidsenKjoellerHelwegLarsen2011} % Danish survey-registry match (DANCOS)





\clearpage
\subsection{Survey Evaluation and Pilot Testing (Week 45)}
\emph{Before we launch a survey on our full sample, how do we check to make sure that it ``works''? What techniques can we use to validate our questionnaire before putting it in the field?}
\vspace{1em}
\subsubsection*{Assignment Due}
Given what you've learned about questionnaire design and survey mode, be prepared to share and briefly present a nearly final and complete version of your questionnaire. You can, of course, still add or delete questions, or change question wordings, response categories, or orderings, but all of the essential questions should be there and you should have a strong idea of the order in which questions will be asked.

\subsubsection*{In-Class Activities}
\begin{itemize*}
\item Try cognitive interviewing in class
\item Develop pre-testing plan for surveys
\end{itemize*}

\subsubsection*{Readings}
\textbook[Ch. 8]{}
\reading{Presseretal2004}
\reading{PresserBlair1994}
\reading{BeattyWillis2007}
\reading{MillerGroves1985} % official records
% focus groups?

%\seealso





\clearpage
\subsection{Interactions with Interviewers or Instruments (Week 46)}
\emph{If a survey is conducted as an interaction between persons (i.e., between a respondent and an interviewer), how does that human interaction affect responding? How do people behave when they are being interviewed? And how do interviewers influence the way that questions are asked and answers are recorded? What can we expect of survey interviewers?}
\vspace{1em}
\subsubsection*{Assignment Due}
In one page, describe a plan for pilot testing your survey. What techniques will you use to assess your questions, your planned survey mode, and the overall quality of your instrument? How many people do you need to pilot the survey on? Be prepared to discuss these plans in detail and revise them in response to feedback during class.

% satisficing
% social desirability bias
% something about survey ethics: we are inviting ourselves into peoples' lives and asking them to reveal things they might not otherwise say

\subsubsection*{In-Class Activities}
\begin{itemize*}
\item Take a survey and record your thoughts and feelings about the instrument
\end{itemize*}

\subsubsection*{Readings}
\textbook[Ch. 9, 11]{}
\reading{Krosnick1991} % satisficing
\reading{RederRitter1992} % Feeling of knowing
\reading{BishopTuchfarberOldendick1986} % fictitious issues
\reading{Davis1997} % race of interviewer
\reading{Prior2009b} % overreported exposure
\reading{JensenThomsen2013} % self-reported cheating
% Krosnick paper on shocking behavior

%\seealso



\clearpage
\subsection{Recruitment and Fielding (Week 47)}
\emph{How do we convince designated respondents to participate in a survey? How do we respond to refusals to participate? How should we monitor the progress of a survey in the field and address challenges faced in the process?}

% recruitment
% interviewing/fielding/training
% interviewer monitoring and reliability checks, interviewer effects, interviewer biases
% disposition codes
% participation incentives
% challenging areas

% choosing designated respondents in non-individual surveys (HH or corporate)

\vspace{1em}
\subsubsection*{Assignment Due}
Considering the feedback on the previous assignment and the new details you've learned about respondent behavior and the interactions between respondents and interviewers, begin implementing the pilot testing of your survey instrument. In one to two written pages, report your initial findings from pilot testing, reflect on what those findings mean for your planned survey, and describe changes you will make to your survey plan based on the pilot testing.

\subsubsection*{In-Class Activities}
\begin{itemize*}
\item Practice writing out recruitment materials
\item Discuss survey fielding scenarios
\item Generate disposition codes for sampled units
\end{itemize*}

\subsubsection*{Readings}
\reading{BelmontReport}
\reading{Dykemaetal2013}
\reading{Kaplowitzetal2012} % invitations
\reading{ConradSchober2000}
\reading{GrantSugarman2004} % incentives/ethics
\reading{DriscollLidow2014} % Mogadishu, Somali paper
\reading{Groves2006} % adaptive survey design

\seealso
\reading{SchoberConrad1997}
\reading{LyallBlairImai2013} % Afghanistan survey experiment
\reading{Linketal2006}
\reading{Stoneetal2014} % longitudinal follow-up
\reading{MartinAbreuWinters2001} % refusal conversion
\reading{Gaziano2005} % designated respondent



\clearpage
\subsection{Data Management I (Week 48)}
\emph{We conduct surveys to make inferences about populations of interest, within a given margin of error. But realities sometimes differ from expectations. What do we do with the data we have? And how do we honestly report our findings?}

% nonresponse: unit/item
% response rate calculation
% attrition
% weighting
% raking?

\subsubsection*{In-Class Activities}
\begin{itemize*}
\item Calculate response rates from disposition codes
\item Generate survey weights
\end{itemize*}

\subsubsection*{Readings}
\textbook[Ch. 6, 10.5]{}
\reading{AAPORStandardDefinitions2011}
\reading{Keeteretal2006}
\reading{Berinsky2002}
\reading{BehrBellgardtRendtel2005}
\reading[Sections 8.4--8.9 (pp. 338--356) from ]{Lohr2009} % weighting, raking

\seealso
\reading{CurtinPresserSinger2005}
\reading{Groves2006}
\reading{Clinton2001} % panel attrition
\reading{BaruchHoltom2008}

\clearpage
\subsection{Data Management II (Week 49)}
\emph{Once we have survey data, what do we do with it? How do we record our questions, answers, and details of sampling and (non)responses? How do we maximize the utility of our data for ourselves, for stakeholders, and for future data end-users?}

\vspace{1em}
\subsubsection*{Assignment Due}
Using your questionnaire (or a subset of 10-20 questions thereof), conduct a pilot interview. Find a friend, family member, or classmate to serve as an interviewer. Explain to them the point of the study, and have them read the questionnaire and ask any clarifying questions. Then, find another friend, family member, or classmate to serve as a respondent. Observe (either in-person or via an audio recording) the survey interview. Discuss with the interviewer and the respondent their reactions to the survey interview (e.g., any points of confusion, whether it was interesting/enjoyable or uninteresting/annoying). In one-page, document what occurred during the interview, note any challenges the interviewer and respondent faced (e.g., did the interviewer change the way the question or response options were worded? did they attempt to clarify meaning?), and reflect on how the pilot testing might lead to any changes in your planned survey.

\subsubsection*{In-Class Activities}
\begin{itemize*}
\item Cleaning, coding, and data imputation
\item Evaluate a published codebook
\item Create a codebook from a questionnaire
\item Anonymizing data
\end{itemize*}

\subsubsection*{Readings}
\textbook[Ch. 10]{}
\reading{Simitis1994} % EU data protection article
\reading{DeBell2013} % coding of open-ended responses
% data management and archiving
%\seealso


\clearpage
\subsection{Final Presentations (Weeks 50--51)}
\vspace{1em}
\subsubsection*{Assignment Due}
Each student will distribute a copy of their survey two days prior to class and then provide a 10 minute presentation of their final exam paper. In the presentation, you should present your research question, sampling plan, and details of the survey mode and questionnaire. Based on details from last week, be prepared to discuss issues of refusals, nonresponse, and dropoff/attrition. When not presenting, students are expected to provide feedback to classmates on their presentations and planned surveys.

\subsubsection*{Readings}
None assigned, though students may distribute surveys or any other materials related to their presentations no later than 24 hours prior to their presentation.



% load bibtext, but don't generate a bibliography
\bibliographystyle{plain}
\nobibliography{Syllabus}

\end{document}
